{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting classifier - ensemble learning\n",
    "## Summary:\n",
    "\n",
    "Interestingly, the hard voting (unweighted) classifier works better than the soft voting (weighted) classifier (0.736 compared to 0.724 accuracy). AdaBoost works better than that with 0.744. The best classifiers are RandomForest and Logistic Regression with 0.748 accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('german.data-numeric.txt',header=None, delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=data.iloc[:,0:24].values\n",
    "y=data[24].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('gnb', GaussianNB(priors=None)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
       "           weights='uniform')), ('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=Tr...f',\n",
       "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb_clf = GaussianNB()\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=4)\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "sgd_clf = SGDClassifier(max_iter=5, random_state=42, loss='modified_huber')\n",
    "svm_clf = SVC(random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('gnb',gnb_clf),('knn',knn_clf),('lr', log_clf), ('sgd', sgd_clf), ('svc', svm_clf)],\n",
    "    voting='hard')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB 0.736\n",
      "GaussianNB              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.85      0.77      0.81       178\n",
      "          2       0.53      0.65      0.59        72\n",
      "\n",
      "avg / total       0.76      0.74      0.74       250\n",
      "\n",
      "GaussianNB [[137  41]\n",
      " [ 25  47]]\n",
      "KNeighborsClassifier 0.696\n",
      "KNeighborsClassifier              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.93      0.81       178\n",
      "          2       0.41      0.12      0.19        72\n",
      "\n",
      "avg / total       0.63      0.70      0.63       250\n",
      "\n",
      "KNeighborsClassifier [[165  13]\n",
      " [ 63   9]]\n",
      "LogisticRegression 0.748\n",
      "LogisticRegression              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.88      0.83       178\n",
      "          2       0.58      0.43      0.50        72\n",
      "\n",
      "avg / total       0.73      0.75      0.74       250\n",
      "\n",
      "LogisticRegression [[156  22]\n",
      " [ 41  31]]\n",
      "SGDClassifier 0.632\n",
      "SGDClassifier              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.65      0.72       178\n",
      "          2       0.40      0.58      0.48        72\n",
      "\n",
      "avg / total       0.68      0.63      0.65       250\n",
      "\n",
      "SGDClassifier [[116  62]\n",
      " [ 30  42]]\n",
      "SVC 0.704\n",
      "SVC              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.96      0.82       178\n",
      "          2       0.42      0.07      0.12        72\n",
      "\n",
      "avg / total       0.63      0.70      0.62       250\n",
      "\n",
      "SVC [[171   7]\n",
      " [ 67   5]]\n",
      "VotingClassifier 0.736\n",
      "VotingClassifier              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.87      0.82       178\n",
      "          2       0.56      0.40      0.47        72\n",
      "\n",
      "avg / total       0.72      0.74      0.72       250\n",
      "\n",
      "VotingClassifier [[155  23]\n",
      " [ 43  29]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in ( gnb_clf, knn_clf, log_clf, sgd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "    print(clf.__class__.__name__, metrics.classification_report(y_test, y_pred))\n",
    "    print(clf.__class__.__name__, metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('gnb', GaussianNB(priors=None)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
       "           weights='uniform')), ('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=Tr...bf',\n",
       "  max_iter=-1, probability=True, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = SVC(probability=True, random_state=42)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('gnb',gnb_clf),('knn',knn_clf),('lr', log_clf), ('sgd', sgd_clf), ('svc', svm_clf)],\n",
    "    voting='soft')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB 0.736\n",
      "GaussianNB              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.85      0.77      0.81       178\n",
      "          2       0.53      0.65      0.59        72\n",
      "\n",
      "avg / total       0.76      0.74      0.74       250\n",
      "\n",
      "GaussianNB [[137  41]\n",
      " [ 25  47]]\n",
      "KNeighborsClassifier 0.696\n",
      "KNeighborsClassifier              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.93      0.81       178\n",
      "          2       0.41      0.12      0.19        72\n",
      "\n",
      "avg / total       0.63      0.70      0.63       250\n",
      "\n",
      "KNeighborsClassifier [[165  13]\n",
      " [ 63   9]]\n",
      "LogisticRegression 0.748\n",
      "LogisticRegression              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.88      0.83       178\n",
      "          2       0.58      0.43      0.50        72\n",
      "\n",
      "avg / total       0.73      0.75      0.74       250\n",
      "\n",
      "LogisticRegression [[156  22]\n",
      " [ 41  31]]\n",
      "SGDClassifier 0.632\n",
      "SGDClassifier              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.65      0.72       178\n",
      "          2       0.40      0.58      0.48        72\n",
      "\n",
      "avg / total       0.68      0.63      0.65       250\n",
      "\n",
      "SGDClassifier [[116  62]\n",
      " [ 30  42]]\n",
      "SVC 0.704\n",
      "SVC              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.96      0.82       178\n",
      "          2       0.42      0.07      0.12        72\n",
      "\n",
      "avg / total       0.63      0.70      0.62       250\n",
      "\n",
      "SVC [[171   7]\n",
      " [ 67   5]]\n",
      "VotingClassifier 0.724\n",
      "VotingClassifier              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.83      0.81       178\n",
      "          2       0.52      0.47      0.50        72\n",
      "\n",
      "avg / total       0.72      0.72      0.72       250\n",
      "\n",
      "VotingClassifier [[147  31]\n",
      " [ 38  34]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (gnb_clf, knn_clf, log_clf, sgd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "    print(clf.__class__.__name__, metrics.classification_report(y_test, y_pred))\n",
    "    print(clf.__class__.__name__, metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 0.748\n",
      "VotingClassifier              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.91      0.84       178\n",
      "          2       0.61      0.35      0.44        72\n",
      "\n",
      "avg / total       0.73      0.75      0.72       250\n",
      "\n",
      "VotingClassifier [[162  16]\n",
      " [ 47  25]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = rnd_clf.predict(X_test)\n",
    "print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "print(clf.__class__.__name__, metrics.classification_report(y_test, y_pred))\n",
    "print(clf.__class__.__name__, metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.5, n_estimators=50, random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 0.744\n",
      "VotingClassifier              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.89      0.83       178\n",
      "          2       0.58      0.39      0.47        72\n",
      "\n",
      "avg / total       0.72      0.74      0.73       250\n",
      "\n",
      "VotingClassifier [[158  20]\n",
      " [ 44  28]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = ada_clf.predict(X_test)\n",
    "print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "print(clf.__class__.__name__, metrics.classification_report(y_test, y_pred))\n",
    "print(clf.__class__.__name__, metrics.confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
